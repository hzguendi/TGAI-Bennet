# TGAI-Bennet Configuration File
# All configurable parameters are defined here

app:
  name: "TGAI-Bennet"
  version: "1.0.0"
  debug: true
  timezone: "Europe/Paris"

llm:
  default_provider: "ollama"  # Options: openai, openrouter, deepseek, ollama
  # default_model comes from OLLAMA_MODEL environment variable
  temperature: 0.7            # LLM temperature setting (0-1)
  max_tokens: 2000           # Maximum tokens per response
  # system_message is defined in chat_history.system_message
  
  providers:
    openai:
      base_url: "https://api.openai.com/v1"
      models:
        - "gpt-3.5-turbo"
        - "gpt-4"
        - "gpt-4-turbo-preview"
    
    openrouter:
      base_url: "https://openrouter.ai/api/v1"
      models:
        - "deepseek/deepseek-r1-distill-qwen-14b:free"
        - "deepseek/deepseek-r1:free"
        #- "openai/gpt-3.5-turbo"
        #- "anthropic/claude-2"
        #- "google/palm-2-chat-bison"
    
    deepseek:
      base_url: "https://api.deepseek.com/v1"
      models:
        - "deepseek-chat"
        - "deepseek-coder"
    
    ollama:
      # base_url comes from OLLAMA_HOST environment variable
      models:
        - "qwen2.5-coder:1.5b"
        - "llama2"
        - "mistral"
        - "codellama"

telegram:
  parse_mode: "Markdown"      # Options: Markdown, HTML, None
  disable_web_page_preview: true
  disable_notification: false
  reply_timeout: 30          # Seconds to wait for bot replies
  max_message_length: 4096   # Maximum message length to send
  
  commands:
    # Admin commands
    reload_modules: "/reload_modules"
    reload_config: "/reload_config" 
    status: "/status"
    stop_bot: "/stop"
    health_check: "/health"

modules:
  enabled: true
  directory: "src/modules"
  hot_reload: true          # Auto-detect and reload modules
  # scan_interval comes from MODULE_CHECK_INTERVAL environment variable
  
  GamingNewsModule:
    enabled: true
    interval_minutes: 3    # 2 hours interval
  
  state_storage:
    enabled: true
    type: "json"            # Options: json, sqlite, redis
    path: "data/module_states.json"
  
  error_handling:
    # max_retries comes from MAX_RETRIES environment variable
    retry_delay: 5          # Seconds between retries
    notify_on_error: true   # Send Telegram message on module errors

  SnarkyMotivatorModule:
    enabled: true
    interval_minutes: 600

logging:
  # level comes from LOG_LEVEL environment variable             # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
  format: "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
  
  file:
    enabled: true
    path: "logs/tgai-bennet.log"
    rotation: "1 day"       # Options: X day(s), X hour(s), X MB
    retention: "30 days"    # How long to keep old logs
    
  module_logging:
    enabled: true
    separate_files: true    # One log file per module
    path_template: "logs/modules/{module_name}.log"

health:
  enabled: true
  # interval comes from HEALTH_CHECK_INTERVAL environment variable             # Seconds between health checks
  
  metrics:
    memory_threshold: 500   # MB, alert if exceeded
    cpu_threshold: 80       # %, alert if exceeded
    disk_threshold: 90      # %, alert if exceeded
  
  notifications:
    telegram_errors: true   # Send errors to Telegram
    log_errors: true        # Log health errors
    
  restarts:
    auto_restart_on_failure: true
    max_restart_attempts: 3
    restart_delay: 30       # Seconds between restart attempts

chat_history:
  enabled: true
  db_path: "data/chat_history.db"
  max_history_length: 10   # Maximum number of messages to keep in context
  max_token_limit: 8000    # Maximum tokens to include in context
  token_safety_margin: 200  # Safety margin for token limit
  prune_strategy: "oldest_first"  # Options: oldest_first, system_first
  
  # Token counting approximations
  system_message_token_base: 50
  user_message_token_base: 20
  assistant_message_token_base: 20
  tokens_per_character: 0.25  # Fallback token estimate per character
  
  # Global system message (can be overridden per module)
  system_message: |
    You are Bennet, a helpful AI assistant in a Telegram chat environment. You're direct, slightly snarky, but always fun and helpful.
    Be concise in your responses as you're operating within Telegram's message constraints.
    Your responses should be informative, helpful, and reflect your friendly but no-nonsense personality.
    
    When responding, provide information that is appropriately detailed for the user's query.
    Try to answer directly without unnecessary hedging or disclaimers unless the topic truly calls for them.
    
    When receiving the history of messages, some of them could be from other modules, so do not let them influence your responses.
    If you're being asked by a module in the system, know that your responses will be sent directly as a Telegram message.

module_defaults:
  time_trigger:
    type: "interval"        # Options: interval, cron
    interval: 300           # Default interval in seconds
    
  event_trigger:
    type: "webhook"         # Options: webhook, file_change, socket
    retry_on_failure: true
    
  api_settings:
    # timeout comes from TIMEOUT_SECONDS environment variable
    # max_retries comes from MAX_RETRIES environment variable
    backoff_factor: 1.5    # Multiplier for exponential backoff
